<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Self-Rationalization in the Wild: A Large Scale Out-of-Distribution Evaluation on NLI-related tasks">
  <meta property="og:title" content="A Large Scale Out-of-Distribution Evaluation of Self-Rationalization on NLI-related tasks"/>
  <meta property="og:description" content="Self-Rationalization, Out-of-Distribution"/>
  <meta property="og:url" content="https://jingyng.github.io/tacl2025-ood-eval-self-rationalization/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Self-Rationalization in the Wild: A Large Scale Out-of-Distribution Evaluation on NLI-related tasks</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Self-Rationalization in the Wild: A Large Scale Out-of-Distribution Evaluation on NLI-related tasks</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://jingyng.github.io/" target="_blank">Jing Yang</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/max-glockner/" target="_blank">Max Glockner</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://www.ic.unicamp.br/~rocha/" target="_blank">Anderson Rocha</a><sup>1</sup>,</span>
                    <span class="author-block">
                      <a href="https://www.informatik.tu-darmstadt.de/ukp/ukp_home/head_ukp/" target="_blank">Iryna Gurevych</a><sup>2</sup>
                  </span>
                  </div>

                  <!-- —— Affiliations ——————————————————————————— -->
                  <div class="publication-affiliations is-size-5">
                    <span class="affiliation-block">
                      <sup>1</sup> Artificial Intelligence Lab (Recod.ai), Institute of Computing, University of Campinas, Brazil
                    </span><br>
                    <span class="affiliation-block">
                      <sup>2</sup> UKP Lab, Department of Computer Science, Technical University of Darmstadt, Germany<br><br>Transactions of the Association for Computational Linguistics (TACL), 2025
                    </span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00741/128862" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/UKPLab/tacl2025-ood-eval-self-rationalization" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2502.04797" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Free-text explanations are expressive and easy to understand, but many datasets lack annotated explanation data, making it challenging to train models for explainable predictions. To address this, we investigate how to use existing explanation datasets for self-rationalization and evaluate models’ out-of-distribution (OOD) performance. We fine-tune T5-Large and OLMo-7B models and assess the impact of fine-tuning data quality, the number of fine-tuning samples, and few-shot selection methods. The models are evaluated on 19 diverse OOD datasets across three tasks: natural language inference (NLI), fact-checking, and hallucination detection in abstractive summarization. For the generated explanation evaluation, we conduct a human study on 13 selected models and study its correlation with the Acceptability score (T5-11B) and three other LLM-based reference-free metrics. Human evaluation shows that the Acceptability score correlates most strongly with human judgments, demonstrating its effectiveness in evaluating free-text explanations. Our findings reveal: 1) few annotated examples effectively adapt models for OOD explanation generation; 2) compared to sample selection strategies, fine-tuning data source has a larger impact on OOD performance; and 3) models with higher label prediction accuracy tend to produce better explanations, as reflected by higher Acceptability scores.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- <section class="section hero is-light" style="margin-bottom: 2em;">
  ...
</section> -->

<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3 has-text-centered">Out-of-distribution evaluation on 19 datasets</h2>
      <!-- Image + caption -->
      <figure class="image">
        <img  src="static/images/tacl_a_00741_i001.png"
              style="max-width:100%; height:auto;">
        <figcaption class="has-text-centered is-size-6 mt-2">
          The table presents the 19 datasets we included in our evaluation, from three tasks: natural language inference, fact-checking and hallucination detection of abstractive summarization.
        </figcaption>
      </figure>
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3 has-text-centered">How much data is needed for generalization?</h2>
      <h2 class="subtitle has-text-justified">
        Is it important to always have more data to fine-tune your model? Not really. In our study, we fine-tuned two open-source models on two data sources, and found that with only 384 samples, the model already reached similar performance as fine-tuning on 50,000 samples.<br>
        <span style="font-weight:bold;"> What about data selection? </span>
        Unfortunately we found that different sample selection methods have much smaller effects compared to data size and source.
      </h2>
      <!-- Image + caption -->
      <figure class="image">
        <img  src="static/images/F1_plot-new.png"
              alt="F1‑score of fine‑tuned models versus training‑set size"
              style="max-width:100%; height:auto;">
        <figcaption class="has-text-centered is-size-6 mt-2">
          Out‑of‑distribution performance of fine‑tuned models on 19 datasets
          covering NLI, fact‑checking and hallucination detection. Colors indicate different data selection methods.
        </figcaption>
      </figure>
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3 has-text-centered">Acceptability score (explanation quality) is positively
        related to label prediction performance</h2>
      <h2 class="subtitle has-text-justified">
        Does explanation improve when models have better performance? Yes, our study shows models that perform better on label prediction also generate better explanations.<br>
      </h2>
      <!-- Image + caption -->
      <figure class="image">
        <img  src="static/images/accept_f1-all.png"
              style="max-width:100%; height:auto;">
        <figcaption class="has-text-centered is-size-6 mt-2">
          Relationship between explanation quality and label prediction performance of models under different fine-tuning factors, with the x-axis showing the Acceptability score, and the y-axis the macro F1 score (scores are averaged over all datasets).
        </figcaption>
      </figure>
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/SY2J0n8Qcq0?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->


<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>
      <iframe  src="static/pdfs/ACL2025_TACL-7401-poster.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{yang2025self,
        title={Self-Rationalization in the Wild: A Large-scale Out-of-Distribution Evaluation on NLI-related tasks},
        author={Yang, Jing and Glockner, Max and Rocha, Anderson and Gurevych, Iryna},
        journal={Transactions of the Association for Computational Linguistics},
        volume={13},
        pages={314--342},
        year={2025},
        publisher={MIT Press}
      }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
